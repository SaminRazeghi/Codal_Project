1- In main.py, you need to set the path to the Ctable.py spider file. For example, if the path is:
    ./codal/Scrappy/codaltable/codaltable/spiders/Ctable.py

    Set the spider_path variable to:
    spider_path = "./codal/Scrappy/codaltable/codaltable"

2- The CSV files generated by the spider will be saved in a folder named "csv" located in the same directory as the Ctable.py spider file. The path to this directory is:
    ./codaltable/codaltable/spiders

3- In runtime.py, there is a method called run_spider which runs a command in the terminal to execute the spider. The command consists of three parts:
    a. First, it changes to the directory where the spider file is located using the cd command:
        cd "{spider_path}"
    b. Second, it runs the scrapy crawl command followed by the name of the spider to execute:
        scrapy crawl {spider_name}
    c. Finally, it passes the url_arguments variable as a parameter to the spider using the -a option:
        -a url_list="{url_arguments}"

    On macOS and Linux, this command works fine. On Windows, you need to replace it with:
            command = cd /d "{spider_path}" && scrapy crawl {spider_name} -a url_list="{url_arguments}"
    This command changes to the directory where the spider is located and also changes the drive if necessary.

4- Run Splash docker image (splash.tar)
5- From https://shecan.ir/ change the DNS
5- Run main.py in venv, and if the path to spider is correct it should run just fine. :)



